{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Архитектура HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDFS хорошо подходит для\n",
    "- Хранение больших файлов:\n",
    "    - Терабайты, петабайты.\n",
    "    - Миллионы, но не миллиарды файлов.\n",
    "    - Файлы размером от 100 мб. Желательно не хранить маленькие файлы.\n",
    "- Стриминг данных:\n",
    "    - Паттерн *write once / read many times*. Лучше не использовать, если данные часто меняются. Пример логов, которые один раз загружены и лежат неизменные.\n",
    "    - Оптимизация под последовательное чтение: нельзя прочитать любое место в файле. HDFS нужен, чтобы хранить большой объем данных и читать большой объем данных. Файл разбит на блоки и блоки читаются последовательно.\n",
    "    - Операция `append` появилась в 0.21."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDFS не подходит для\n",
    "- Low-latency reads (если нужно быстро получать данные, то HDFS не подходит):\n",
    "    - Высокая пропускная способность вместо быстрого доступа к данным. Для web сервисов не подойдет.\n",
    "    - HBase помогает решать эту задачу.\n",
    "- Большое количество небольших файлов\n",
    "    - Лучше миллион больших файлов, чем миллиард маленьких (лучше 1000 по 1гб, чем 100 000 по 10мб).\n",
    "- Многопоточная запись\n",
    "    - Один процесс записи на файл.\n",
    "    - Данные дописываются в конец файла, если нужно в середину, то это сделать нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daemons (демоны) HDFS\n",
    "\n",
    "<img src=\"schemas/hdfs_demons.svg\" title=\"Демоны HDFS\" width=\"400\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Демоны процессов - это такие процессы, которые постоянно запущены в системе и выполняют какие-то функции.\n",
    "\n",
    "3 типа demon процессов:\n",
    "- Namenode\n",
    "- Datanode\n",
    "- Secondary node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Namenode\n",
    "\n",
    "Главный процесс в HDFS. Запускается на 1-ой (выделенной) машине. Не хранит никакие данные, а отвечает за метаинформацию. Знает все о структуре файловой системы: иерархию файлов и директорий, как файл разбит на блоки, где эти блоки и их реплики находятся (на каких серверах). При этом Namenode знает сколько всего свободного места в кластере и на каждом сервере. Namenode хранит все в памяти для получения быстрого доступа на чтение и изменение файловой структуры. \n",
    "\n",
    "Отвечает за:\n",
    "- файловое пространства (namespace)\n",
    "- мета-информацию\n",
    "- расположение блоков файлов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datanode\n",
    "\n",
    "Запущен на каждой машине кластера и отвечает за хранение информации на данной машине. Отправляет сигналы о состоянии в Namenode.\n",
    "\n",
    "- Хранит и отдает блоки данных\n",
    "- Отправляет ответы о состоянии на Namenode\n",
    "- Запускается на каждой машине кластера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary Namenode\n",
    "\n",
    "- Периодически обновляет fsimage\n",
    "- Требует то же железо, что и Namenode\n",
    "- (!) Не используется для high-availability, т.е. это не backup для Namenode\n",
    "\n",
    "Secondary NN не является полноценным бекап сервером, он обеспечивает быстрое восстановление основного NN. В новых версиях hdfs есть полноценный stadby бекап сервер. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Файлы и блоки\n",
    "\n",
    "- Файлы в HDFS состоят из блоков (единица хранения данных)\n",
    "- Управляется через Namenode\n",
    "- Хранится на Datanode\n",
    "\n",
    "Задача: клиенту нужно прочитать файл.  \n",
    "Workflow: \n",
    "- идет к демону Namenode\n",
    "- узнает из каких блоков состоит файл\n",
    "- узнает на каких серверах лежат данные блоки\n",
    "- общается с datanode, чтобы прочитать нужные блоки файла\n",
    "\n",
    "Данные реплицируются по машинам в процессе записи:\n",
    "- Один и тот же блок хранится на нескольких Datanode\n",
    "- Фактор репликации по умолчанию равен 3\n",
    "- Это нужно для fault-tolerance и упрощения доступа\n",
    "\n",
    "Стандартный размер блока 64mb или 128mb. Основной мотив - снизить стоимость seek time (перемещение головки диска) по сравнению со скоростью передачи данных (transfer rate):\n",
    "- `Time to transfer` > `Time to seek`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Репликация блоков\n",
    "\n",
    "- Namenode определяет, где располагать блоки.\n",
    "- Баланс между надежностью и производительностью:\n",
    "    - Попытка снизить нагрузку на сеть (bandwidth)\n",
    "    - Попытка улучшить надежность в разных стойках\n",
    "    \n",
    "Фактор репликации равен 3:\n",
    "- 1-я репликация на локальную машину\n",
    "- 2-я репликация на другую машину из той же стойки\n",
    "- 3-я репликация на машину из другой стойки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Взаимодействие клиента и демонов\n",
    "\n",
    "Как происходит процесс чтения:\n",
    "- Обращаемся к Namenode и получаем информацию о нахождении блоков\n",
    "- ОБращаемся к блокам и читаем файлы\n",
    "\n",
    "Как происходит процесс записи и репликации:\n",
    "- Клиент делает запрос к Namenode на создание блока. Namenode определяет, на каких хостах должны быть расположены реплики и передает эту информацию клиенту.\n",
    "- Клиент начинает писать данные блока на первую ноду из списка и сообщает Datanode, на какой следующий хост нужно реплицировать данные. Запись происходит небольшими порциями (по 4Кб). После получения каждой порции данных, Datanode передает ее следующей Datanode из списка.\n",
    "- Вторая Datanode также получает данные порциями и передает их следующей Datanode.\n",
    "- Таким образом получается некий pipe, данные в котором передаются последовательно по цепочки по всему списку хостов, на которых должны находится реплики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача\n",
    "\n",
    "Пользователь делает следующие действия в hdfs:\n",
    "- Записывает файл /tmp/log.txt\n",
    "- Устанавливает у этого файла фактор репликации 2\n",
    "- Перемещает этот файл в /data/log.txt\n",
    "- Выводит содержимое файла /data/log.txt на экран\n",
    "- Удаляет файл /data/log.txt\n",
    "\n",
    "Понятно, что при выполнении каждого действия происходит обращение к демону NameNode. А сколько при этом происходит обращений к DataNode?\n",
    "\n",
    "Напишите минимальное необходимое число обращений клиента к демонам DataNode для выполнения этих действий. \n",
    "\n",
    "Ответ: 2. Потому что установка фактора репликации, перемещение и удаление это работа с метаинформацией. А при работе с ней мы работаем только с namenode. Все остальные обращения к датанодам делает уже сама namenode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Namenode: использование памяти\n",
    "\n",
    "Для быстрого доступа вся мета-информация о блоках хранится в ОЗУ Namenode:\n",
    "- Чем больше кластер, теми больше ОЗУ требуется"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доступ к HDFS\n",
    "\n",
    "- Direct Access\n",
    "    - Взаимодействует с HDFS с помощью нативного клиента\n",
    "    - Java, C++\n",
    "\n",
    "<img src=\"schemas/direct_access.svg\" title=\"Демоны HDFS\" width=\"400\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proxy Server\n",
    "    - Доступ к HDFS через Proxy server - middle man\n",
    "    - Серверы REST API (ответы в формате JSON, XML или ProtoBuf), Thrift (язык определения интерфейса) и Avro (механизм сериализации)\n",
    "    \n",
    "    \n",
    "<img src=\"schemas/proxy_server.svg\" title=\"Демоны HDFS\" width=\"400\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Shell-команды\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hdfs dfs -<command> -<option> <URI>`\n",
    "\n",
    "Просмотр корневой директории `hdfs dfs -ls /`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URI\n",
    "\n",
    "Для того чтобы ссылка считалась URI необходимо наличие:\n",
    "- либо `scheme` + `authority` + `path`,\n",
    "- либо `sheme` + `path`,\n",
    "- либо только `path`.\n",
    "\n",
    "`hdfs://localhost:8020/user/home`  \n",
    "schema + authority + HDFS path\n",
    "\n",
    "- Local\n",
    "```bash\n",
    "# schema file:///\n",
    "# path //to/path/file3\n",
    "hdfs dfs -ls file:///to/path/file3\n",
    "```\n",
    "\n",
    "- HDFS:\n",
    "```bash\n",
    "hdfs dfs -ls hdfs://localhost/to/path/dir\n",
    "```\n",
    "\n",
    "Запись в конфиге, чтобы не обращаться к схеме:\n",
    "```\n",
    "fs.default.name=hdfs://localhost\n",
    "#hdfs dfs -ls /to/path/dir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Команды в shell\n",
    "\n",
    "- Похожие на команды Unix:\n",
    "```\n",
    "cat, rm, ls, du ...\n",
    "```\n",
    "- Поддержка специфичных для HDFS операций:\n",
    "`setrep - смена фактора репликаций`\n",
    "\n",
    "Вывод списка команд: `hdfs dfs -help <command_name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# ls -- листинг директории и статистика файлов\n",
    "# -R статистика по директории\n",
    "hadoop fs -ls -R /path\n",
    "\n",
    "# mkdir -- создание новой директории\n",
    "hadoop fs –mkdir /path/directory_name\n",
    "\n",
    "# cat -- вывод источника в stdout\n",
    "# вывод всех строчек нецелесообразен, нужно ограничить\n",
    "hdfs dfs -cat /dir/file.txt | head -n 100\n",
    "\n",
    "# text -- аналог cat, но работает с архивами\n",
    "hdfs dfs -text /dir/file.gz\n",
    "\n",
    "# tail -- выводит последние строчки файлов\n",
    "hdfs dhs -tail /dir/file.txt\n",
    "\n",
    "# cp -- копирование файл из одного места в другое\n",
    "# годится только для небольших файлов, тк копируются все блоки и тд\n",
    "hdfs dfs -cp /dir/file1 /otherDir/file2\n",
    "\n",
    "# distcp -- копирование больших файлов или много файлов за раз\n",
    "# копируются блоки параллельно\n",
    "hdfs distcp /dir/file1 /otherDir/file2\n",
    "\n",
    "# mv -- перемещение файла из одного места в другое\n",
    "# физического перемещения не происходит, мы указываем Namenode новое расположение\n",
    "hdfs dfs -mv /dir/file1 /dir2\n",
    "\n",
    "# put (copyFromLocal) -- копирование локального файла в HDFS\n",
    "hdfs dfs -put localfile /dir/file\n",
    "\n",
    "# get (copyToLocal) -- копирование файла из HDFS на локальную машину\n",
    "hdfs dfs -get /dir/file localfile\n",
    "\n",
    "# rm -- удалить файл (в корзину)\n",
    "hdfs dfs -rm /dir/file\n",
    "# рекурсивно директорию\n",
    "hdfs dfs -rm -R /dir\n",
    "\n",
    "# du -- размер файла или директории в байтах\n",
    "hdfs dfs -du /dir/\n",
    "\n",
    "# chmod, chown -- права доступа и владелец файла\n",
    "# count -- количество файлов в директории\n",
    "# test -- существует ли файл в директории\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Команды администрирования HDFS\n",
    "\n",
    "```bash\n",
    "# fsck (расш. file system check) -- проверка файловой системы\n",
    "# Отсутствующие блоки\n",
    "# Недореплицированные блоки\n",
    "hdfs fsck /\n",
    "\n",
    "# DFSAdmin -- администрирование HDFS\n",
    "hdfs dfsadmin -<command>\n",
    "# -report -- отображает статистику по HDFS\n",
    "# -safemode -- включение безопасного режима для проведения административных работ upgrade, backup ...\n",
    "\n",
    "# Balancer -- утилита, которая автоматически анализирует расположение блоков в HDFS и старается его сбалансировать. Блоки в HDFS могут быть неравномерно распределены по всем Datanode-ам кластера\n",
    "hdfs balancer \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Java API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
